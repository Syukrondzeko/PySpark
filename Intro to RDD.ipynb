{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 11:57:02) [GCC 12.3.0]\n",
      "PySpark version\n",
      "3.5.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python version\")\n",
    "print(sys.version)\n",
    "\n",
    "import pyspark\n",
    "print(\"PySpark version\")\n",
    "print(pyspark.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Spark Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "\n",
    "master = \"local[*]\"\n",
    "app_name = \"Introduction to Apache Spark\"\n",
    "spark_conf = SparkConf().setMaster(master).setAppName(app_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "at7TZhcCFIeg"
   },
   "source": [
    "## 2. SparkContext and SparkSession\n",
    "\n",
    "The class `pyspark.SparkContext` creates a client which connects to a Spark cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Method 1: Using SparkSession\n",
    "# spark = SparkSession.builder.config(conf=spark_conf).getOrCreate()\n",
    "# sc = spark.sparkContext\n",
    "# sc.setLogLevel('ERROR')\n",
    "\n",
    "# Method 2: Getting or instantiating a SparkContext\n",
    "sc = SparkContext.getOrCreate(spark_conf)\n",
    "sc.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uDMpTDX_FIel"
   },
   "source": [
    "## 3. Create an RDD object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aLTAGst8FIem"
   },
   "source": [
    ". This client can be used to create an RDD object. There are two methods from this class for directly creating RDD objects:\n",
    "* `parallelize()`\n",
    "* `textFile()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "733bde-NFIen"
   },
   "source": [
    "### 3.1. parallelize()\n",
    "\n",
    "- `parallelize()` distribute a local **python collection** to form an RDD. Common built-in python collections include `list`, `tuple` or `set`.\n",
    "- By default the number of partitions will be the number of threads. The function parallelize can have a second argument to indicate manually how many\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SOkblJ8jFIeo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw list: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "\n",
      "Default partitions:  8\n",
      "Manual partitions:  5 \n",
      "\n",
      "rdd data: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "## FROM LIST\n",
    "data = [i for i in range(20)]\n",
    "print(f'raw list: {data}\\n')\n",
    "\n",
    "rdd = sc.parallelize(data)\n",
    "print('Default partitions: ',rdd.getNumPartitions())\n",
    "\n",
    "rdd = sc.parallelize(data,5)\n",
    "print('Manual partitions: ',rdd.getNumPartitions(),'\\n')\n",
    "\n",
    "# Show the data\n",
    "print(f'rdd data: {rdd.collect()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "toJd7qolFIeu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw list of tuple: [('cat', 'dog', 'fish'), ('orange', 'apple')]\n",
      "rdd data: [('cat', 'dog', 'fish'), ('orange', 'apple')]\n",
      "\n",
      "raw set: {'cat', 'fish', 'dog'}\n",
      "rdd data: ['cat', 'fish', 'dog']\n"
     ]
    }
   ],
   "source": [
    "## FROM LIST OF TUPLE\n",
    "data = [('cat', 'dog', 'fish'), ('orange', 'apple')]\n",
    "print(f'raw list of tuple: {data}')\n",
    "rdd = sc.parallelize(data)\n",
    "print(f'rdd data: {rdd.collect()}\\n')\n",
    "\n",
    "## FROM A SET\n",
    "data = {'cat', 'dog', 'fish', 'cat', 'dog', 'dog'}\n",
    "print(f'raw set: {data}')\n",
    "rdd = sc.parallelize(data)\n",
    "print(f'rdd data: {rdd.collect()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eEwVxVkbFIe5"
   },
   "source": [
    "### 3.2. textFile()\n",
    "\n",
    "- The `textFile()` function reads a text file and returns it as an **RDD of strings**.\n",
    "- Usually, you will need to apply some **map** functions to transform each elements of the RDD to some data structure/type that is suitable for data analysis.\n",
    "- When using `textFile()`, each line of the text file becomes an element in the resulting RDD.\n",
    "- Read a txt file, you can use the same function for a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ifFjwci2FIe_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default partitions:  2\n",
      "Manual partitions:  5 \n",
      "\n",
      "Here is the data: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['James Edward Harden Jr. (born August 26, 1989) is an American professional basketball player for the Los Angeles Clippers of the National Basketball Association (NBA)',\n",
       " 'He is widely regarded as one of the greatest scorers and shooting guards in NBA history.',\n",
       " \"In 2021, Harden was honored as one of the league's top 75 players by being named to the NBA 75th Anniversary Team.\",\n",
       " 'Harden played college basketball for the Arizona State Sun Devils, where he was named a consensus All-American and Pac-10 Player of the Year in 2009.',\n",
       " '',\n",
       " 'Harden was selected with the third overall pick in the 2009 NBA draft by the Oklahoma City Thunder.',\n",
       " '',\n",
       " '',\n",
       " 'In 2012, he was named NBA Sixth Man of the Year and helped Oklahoma City reach the NBA Finals, where they lost to the Miami Heat in five games.',\n",
       " 'After the Thunder refused to offer him a max contract extension after lost to Miami, Harden was unwilling to take a pay cut and was subsequently traded to the Houston Rockets before the 2012–13 season.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.textFile('harden.txt')\n",
    "print('Default partitions: ',rdd.getNumPartitions())\n",
    "\n",
    "# with number of partitions for the data\n",
    "rdd = sc.textFile('harden.txt', 5)\n",
    "\n",
    "# Verify the new number of partitions of the data \n",
    "print('Manual partitions: ',rdd.getNumPartitions(),\"\\n\")\n",
    "\n",
    "print(\"Here is the data: \")\n",
    "rdd.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "EmKZ6umtFIfD",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## 4. RDD Operations\n",
    "RDDs support two types of operations: \n",
    "- Transformations (operations on RDDs that return a new RDD, such as `map()` and `filter()`)\n",
    "- Actions (not return new RDD, such as `count()` and `first()`)\n",
    "\n",
    "**Element-wise transformations:**\n",
    "\n",
    "* `map()`\n",
    "* `mapValues()`\n",
    "* `flatMap()`\n",
    "* `flatMapValues()`\n",
    "\n",
    "### 4.1. map\n",
    "\n",
    "The `map()` method applies a function to each elements of the RDD. Each element has to be a valid input to the function. The returned RDD has the function outputs as its new elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k8SeuaXWFIfD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default partitions:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Name,Shoot,Dribble,Dunk,Defence',\n",
       " 'James Harden,90,85,80,65',\n",
       " 'Kevin Durant,95,80,90,85',\n",
       " 'Stephen Curry,99,85,70,80',\n",
       " 'Lebron James,85,80,99,95']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data into RDD\n",
    "\n",
    "rdd = sc.textFile('nba.csv')\n",
    "print('Default partitions: ',rdd.getNumPartitions())\n",
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['James Harden,90,85,80,65',\n",
       " 'Kevin Durant,95,80,90,85',\n",
       " 'Stephen Curry,99,85,70,80',\n",
       " 'Lebron James,85,80,99,95',\n",
       " 'Kyre Irving,88,99,80,80']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Remove header\n",
    "\n",
    "def removeHeaderRow(rdd):\n",
    "    header = rdd.first()\n",
    "    return rdd.filter(lambda x: x != header)\n",
    "    \n",
    "rdd_1 = removeHeaderRow(rdd)\n",
    "rdd_1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('James Harden', ['90', '85', '80', '65']),\n",
       " ('Kevin Durant', ['95', '80', '90', '85']),\n",
       " ('Stephen Curry', ['99', '85', '70', '80']),\n",
       " ('Lebron James', ['85', '80', '99', '95']),\n",
       " ('Kyre Irving', ['88', '99', '80', '80'])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Split NBA player name with his rating\n",
    "\n",
    "def parseRecord(line):\n",
    "    array_line = line.split(',')\n",
    "    return (array_line[0], array_line[1:])\n",
    "    \n",
    "rdd_2 = rdd_1.map(parseRecord)\n",
    "rdd_2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LATcRl6kFIfM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('James Harden', [90.0, 85.0, 80.0, 65.0]),\n",
       " ('Kevin Durant', [95.0, 80.0, 90.0, 85.0]),\n",
       " ('Stephen Curry', [99.0, 85.0, 70.0, 80.0]),\n",
       " ('Lebron James', [85.0, 80.0, 99.0, 95.0]),\n",
       " ('Kyre Irving', [88.0, 99.0, 80.0, 80.0])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convert string values to numeric values\n",
    "\n",
    "rdd_3 = rdd_2.map(lambda x: (x[0], list(map(float, x[1]))))\n",
    "rdd_3.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yVWYWwzMFIfR"
   },
   "source": [
    "### 4.2 `mapValues`\n",
    "\n",
    "The `mapValues` function requires that each element in the RDD has a **key/value** pair structure, for example, a tuple of 2 items, or a list of 2 items. The `mapValues` function applies a function to each of the element values. The element key will remain unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xPpCrsq6FIfV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('James Harden', 80.0),\n",
       " ('Kevin Durant', 87.5),\n",
       " ('Stephen Curry', 83.5),\n",
       " ('Lebron James', 89.75),\n",
       " ('Kyre Irving', 86.75)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "rdd_4 = rdd_3.mapValues(lambda x: np.mean(x))\n",
    "rdd_4.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K2QtBnKgFIfa"
   },
   "source": [
    "### 4.3 `flatMap`\n",
    "\n",
    "This function first applies a function to each elements of an RDD and then flatten the results. We can simply use this function to flatten elements of an RDD without extra operation on each elements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1146,
     "status": "error",
     "timestamp": 1558931233482,
     "user": {
      "displayName": "jabed morshed",
      "photoUrl": "https://lh6.googleusercontent.com/-zpjDVKMUu-A/AAAAAAAAAAI/AAAAAAAAGmE/SyAhbS9nnhk/s64/photo.jpg",
      "userId": "00903852887354341760"
     },
     "user_tz": -600
    },
    "id": "weZ5T7uxFIfc",
    "outputId": "e05c0d94-78c2-49ce-c716-94f2082e6eac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before flatMap: \n",
      "[('Stephen Curry', 'Klay Thompson'), ('Paul George', 'James Harden', 'Russel Westbrook', 'Kawhi Leonard'), ('Giannis Antetokuonmpo', 'Damian Lilliard')]\n",
      "\n",
      "After flatMap: \n",
      "['Stephen Curry', 'Klay Thompson', 'Paul George', 'James Harden', 'Russel Westbrook', 'Kawhi Leonard', 'Giannis Antetokuonmpo', 'Damian Lilliard']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [('Stephen Curry', 'Klay Thompson'), ('Paul George', 'James Harden', 'Russel Westbrook', 'Kawhi Leonard'), ('Giannis Antetokuonmpo', 'Damian Lilliard')]\n",
    "rdd_5 = sc.parallelize(data)\n",
    "print(f'Before flatMap: \\n{rdd_5.collect()}\\n')\n",
    "\n",
    "rdd_5 = rdd_5.flatMap(lambda x: x)\n",
    "print(f'After flatMap: \\n{rdd_5.collect()}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kL88Q46yFIfh"
   },
   "source": [
    "### 4.5 `flatMapValues`\n",
    "\n",
    "The `flatMapValues` function requires that each element in the RDD has a **key/value** pair structure. It applies a function to each **element value** of the RDD object and then flatten the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KXmkMaHlFIfh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['James Harden', (90.0, 85.0, 80.0, 65.0)],\n",
       " ['Kevin Durant', (95.0, 80.0, 90.0, 85.0)],\n",
       " ['Stephen Curry', (99.0, 85.0, 70.0, 80.0)]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    [\"James Harden\", (90.0, 85.0, 80.0, 65.0)],\n",
    "    [\"Kevin Durant\", (95.0, 80.0, 90.0, 85.0)],\n",
    "    [\"Stephen Curry\", (99.0, 85.0, 70.0, 80.0)]\n",
    "]\n",
    "rdd_6 = sc.parallelize(data)\n",
    "rdd_6.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vKO9_LmEFIfk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('James Harden', ('Shoot', 90.0)),\n",
       " ('James Harden', ('Dribble', 85.0)),\n",
       " ('James Harden', ('Dunk', 80.0)),\n",
       " ('James Harden', ('Defence', 65.0)),\n",
       " ('Kevin Durant', ('Shoot', 95.0)),\n",
       " ('Kevin Durant', ('Dribble', 80.0)),\n",
       " ('Kevin Durant', ('Dunk', 90.0)),\n",
       " ('Kevin Durant', ('Defence', 85.0)),\n",
       " ('Stephen Curry', ('Shoot', 99.0)),\n",
       " ('Stephen Curry', ('Dribble', 85.0)),\n",
       " ('Stephen Curry', ('Dunk', 70.0)),\n",
       " ('Stephen Curry', ('Defence', 80.0))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_6 = rdd_6.flatMapValues(lambda x: list(zip([\"Shoot\", \"Dribble\", \"Dunk\", \"Defence\"], x)))\n",
    "rdd_6.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6M-PLissFIfm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['James Harden', 'Shoot', 90.0],\n",
       " ['James Harden', 'Dribble', 85.0],\n",
       " ['James Harden', 'Dunk', 80.0],\n",
       " ['James Harden', 'Defence', 65.0],\n",
       " ['Kevin Durant', 'Shoot', 95.0],\n",
       " ['Kevin Durant', 'Dribble', 80.0],\n",
       " ['Kevin Durant', 'Dunk', 90.0],\n",
       " ['Kevin Durant', 'Defence', 85.0],\n",
       " ['Stephen Curry', 'Shoot', 99.0],\n",
       " ['Stephen Curry', 'Dribble', 85.0],\n",
       " ['Stephen Curry', 'Dunk', 70.0],\n",
       " ['Stephen Curry', 'Defence', 80.0]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpack the element values\n",
    "rdd_6 = rdd_6.map(lambda x: [x[0]] + list(x[1]) )\n",
    "rdd_6.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6. Accumulator\n",
    "\n",
    "Accumulators provides a simple syntax for aggregating values from worker nodes back to the driver program.\n",
    "They are only “added” to through an associative and commutative operation and can therefore be efficiently supported in parallel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blank lines: 0\n"
     ]
    }
   ],
   "source": [
    "## This code will produce an unexpected result\n",
    "\n",
    "rdd_7 = sc.textFile('harden.txt', 3)\n",
    "blank_lines = 0 # global variable\n",
    "\n",
    "def extract_blank_lines(line):\n",
    "    global blank_lines\n",
    "    if line == \"\":\n",
    "        blank_lines += 1\n",
    "    return line.split(\" \")\n",
    "        \n",
    "rdd_7 = rdd_7.flatMap(extract_blank_lines)\n",
    "rdd_7.collect()\n",
    "\n",
    "print(\"Blank lines: %d\" %blank_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blank lines: 3\n"
     ]
    }
   ],
   "source": [
    "rdd_7 = sc.textFile('harden.txt', 3)\n",
    "blank_lines = sc.accumulator(0) # Create Accumulator[int] intitialized to 0\n",
    "\n",
    "def extract_blank_lines(line):\n",
    "    global blank_lines\n",
    "    if line == \"\":\n",
    "        blank_lines += 1\n",
    "    return line.split(\" \")\n",
    "        \n",
    "rdd_7 = rdd_7.flatMap(extract_blank_lines)\n",
    "rdd_7.collect()\n",
    "\n",
    "print(\"Blank lines: %d\" %blank_lines.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City words: 3\n"
     ]
    }
   ],
   "source": [
    "city_words = {'Oklahoma', 'Los Angeles', 'Miami', 'New York'}\n",
    "city_words_count = sc.accumulator(0)\n",
    "\n",
    "broadcast_city_words = sc.broadcast(city_words)\n",
    "\n",
    "rdd_8 = sc.textFile('harden.txt', 3)\n",
    "rdd_8.collect()\n",
    "\n",
    "def check_city_words(line):\n",
    "    global city_words_count\n",
    "    words = line.split(\" \")\n",
    "    for word in words:\n",
    "        if word in broadcast_city_words.value: # using the broadcast variable in the function that runds on the cluster\n",
    "            city_words_count += 1\n",
    "            \n",
    "rdd_8 = rdd_8.filter(check_city_words)\n",
    "rdd_8.collect()\n",
    "\n",
    "print(\"City words: %d\" %city_words_count.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Visualisation of parallelism execution in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the SparkContext\n",
    "sc.stop()\n",
    "\n",
    "# Start new SparkContext\n",
    "sc = SparkContext.getOrCreate(spark_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default partitions:  5\n"
     ]
    }
   ],
   "source": [
    "# We will copy the previous code that reads the file mtcars.csv\n",
    "rdd = sc.textFile('nba.csv',5)\n",
    "\n",
    "header = rdd.first()\n",
    "rdd_1 = rdd.filter(lambda x: x != header)\n",
    "\n",
    "# parseRecord is already implemented\n",
    "rdd_2 = rdd_1.map(parseRecord)\n",
    "rdd_3 = rdd_2.map(lambda x: (x[0], list(map(float, x[1]))))\n",
    "\n",
    "# Verify the number of partitions\n",
    "print('Default partitions: ',rdd.getNumPartitions())\n",
    "\n",
    "# Open localhost:4040"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('James Harden', [90.0, 85.0, 80.0, 65.0]),\n",
       " ('Kevin Durant', [95.0, 80.0, 90.0, 85.0]),\n",
       " ('Stephen Curry', [99.0, 85.0, 70.0, 80.0]),\n",
       " ('Lebron James', [85.0, 80.0, 99.0, 95.0]),\n",
       " ('Kyre Irving', [88.0, 99.0, 80.0, 80.0]),\n",
       " ('Kyle Thompson', [95.0, 80.0, 80.0, 85.0]),\n",
       " ('Luka Doncic', [88.0, 80.0, 85.0, 80.0]),\n",
       " ('Vucevic', [75.0, 75.0, 85.0, 90.0])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform collect() action to execute the job\n",
    "rdd_3.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "yVWYWwzMFIfR",
    "K2QtBnKgFIfa",
    "kL88Q46yFIfh",
    "48_7UVktFIgD",
    "dtN67ydpFIgF",
    "cSs0qd02FIgI"
   ],
   "name": "FIT5202 - Getting started with Apache Spark.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
